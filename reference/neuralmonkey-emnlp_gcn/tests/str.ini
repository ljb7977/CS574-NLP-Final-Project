;; Small training test

[main]
name="scene text recognition"
tf_manager=<tf_manager>
output="tests/outputs/str"
overwrite_output_dir=True
batch_size=4
epochs=2
train_dataset=<train_data>
val_dataset=<val_data>
trainer=<trainer>
runners=[<runner>]
postprocess=None
evaluation=[("target_chars", evaluators.edit_distance.EditDistance)]
logging_period=1
validation_period=4
runners_batch_size=5
test_datasets=[<val_data>,<val_data_no_target>]
random_seed=1234

[tf_manager]
class=tf_manager.TensorFlowManager
num_threads=4
num_sessions=1

[image_reader]
class=readers.image_reader.image_reader
prefix="tests/data/str"
pad_h=31
pad_w=310
mode="F"

[train_data]
class=dataset.load_dataset_from_files
s_images=("tests/data/str/train_files.txt", <image_reader>)
s_target="tests/data/str/train_words.txt"
preprocessors=[("target", "target_chars", processors.helpers.preprocess_char_based)]
lazy=False

[val_data]
; Validation data, the languages are not necessary here, encoders and decoders
; access the data series via the string identifiers defined here.
class=dataset.load_dataset_from_files
s_images=("tests/data/str/val_files.txt", <image_reader>)
s_target="tests/data/str/val_words.txt"
preprocessors=[("target", "target_chars", processors.helpers.preprocess_char_based)]

[val_data_no_target]
; Validation data, the languages are not necessary here, encoders and decoders
; access the data series via the string identifiers defined here.
class=dataset.load_dataset_from_files
s_images=("tests/data/str/val_files.txt", <image_reader>)

[encoder]
class=encoders.cnn_encoder.CNNEncoder
name="cnn"
data_id="images"
image_height=31
image_width=310
pixel_dim=1
convolutions=[(3, 3, None), (3, 3, 2)]
fully_connected=[4,2]

[decoder_vocabulary]
class=vocabulary.from_dataset
datasets=[<train_data>]
series_ids=["target_chars"]
max_size=70
save_file="tests/outputs/str/decoder_vocabulary.pickle"
overwrite=True

[decoder]
class=decoders.decoder.Decoder
name="decoder"
encoders=[<encoder>]
rnn_size=8
embedding_size=9
use_attention=True
dropout_keep_prob=0.5
data_id="target_chars"
max_output_len=10
vocabulary=<decoder_vocabulary>

[trainer]
class=trainers.cross_entropy_trainer.CrossEntropyTrainer
decoders=[<decoder>]
l2_weight=1.0e-8
clip_norm=1.0
optimizer=<adadelta>

[adadelta]
class=config.utils.adadelta_optimizer
epsilon=1.0e-6
rho=0.95

[runner]
class=runners.runner.GreedyRunner
decoder=<decoder>
output_series="target_chars"
