
[main]
name=multi objective task
output=out-example-multiobjective
encoders=[<encoder>]
decoder=<decoder_joint>
runner=<runner>
evaluation=[<bleu1>, <bleu4>]
threads=4
batch_size=128
epochs=10
train_dataset=<train_data>
val_dataset=<val_data>
trainer=<trainer>
validation_period=1000
logging_period=20

[bleu1]
class=evaluators.bleu.BLEUEvaluator
n=1

[bleu4]
class=evaluators.bleu.BLEUEvaluator
n=4


; Tags are in the source language, but we deal with them as outputs, so we don't call them
; source or target, as both are confusing.

[train_data]
class=dataset.load_dataset_from_files
s_source=examples/data/pcedt2/train.forms-en.txt
s_tags=examples/data/pcedt2/train.tags-en.txt
s_target=examples/data/pcedt2/train.forms-cs.txt
;preprocessor=<bpe_preprocess>

[val_data]
class=dataset.load_dataset_from_files
s_source=examples/data/pcedt2/val.forms-en.txt
s_tags=examples/data/pcedt2/val.tags-en.txt
s_target=examples/data/pcedt2/val.forms-cs.txt
;preprocessor=<bpe_preprocess>

[source_vocabulary]
class=vocabulary.from_dataset
datasets=[<train_data>]
series_ids=[source]
max_size=30000

[target_vocabulary]
class=vocabulary.from_dataset
datasets=[<train_data>]
series_ids=[target]
max_size=30000

[tags_vocabulary]
class=vocabulary.from_dataset
datasets=[<train_data>]
series_ids=[tags]
max_size=50

[encoder]
class=encoders.sentence_encoder.SentenceEncoder
rnn_size=300
max_input_len=50
embedding_size=300
dropout_keep_prob=0.8
attention_type=decoding_function.Attention
data_id=source
vocabulary=<source_vocabulary>


; This is the new class that runs several decoders.
[decoder_joint]
class=decoders.multi_decoder.MultiDecoder
main_decoder=<decoder_target>
regularization_decoders=[<decoder_tags>]

[decoder_target]
class=decoders.decoder.Decoder
encoders=[<encoder>]
rnn_size=300
;For target embeddings: this defines the representation used for previously decoded words.
embedding_size=300
use_attention=True
dropout_keep_prob=0.8
data_id=target
vocabulary=<target_vocabulary>
max_output_len=50

[decoder_tags]
class=decoders.sequence_labeler.SequenceLabeler
encoder=<encoder>
hidden_layer_size=100
data_id=tags
vocabulary=<tags_vocabulary>

[trainer]
class=trainers.cross_entropy_trainer.CrossEntropyTrainer
decoder=<decoder_joint>
l2_regularization=1.0e-8

[runner]
class=runners.runner.GreedyRunner
decoder=<decoder_joint>
batch_size=256
